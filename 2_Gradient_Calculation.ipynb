{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgnEyjYqTYSZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to calculate gradient of some function wrt x.\n",
        "\n",
        "By default, **requires_grad=False**"
      ],
      "metadata": {
        "id": "SIElIiz9To5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(3, ), requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrVTlZHjTfY-",
        "outputId": "955cd407-7baf-4608-c687-8e6128645320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4415,  0.0681, -0.4358], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A computational graph will be created.\n",
        "\n",
        "Since, + operation is used. Therefore **grad_fn=\\<AddBackward0\\>**"
      ],
      "metadata": {
        "id": "bL3hyLjJ9B-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "id": "t6drPjfCTitc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5c0850-3fa7-4099-c4e3-6cc63fdb4f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5585, 2.0681, 1.5642], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating gradients"
      ],
      "metadata": {
        "id": "x-jaZ2Lv-GfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad can be implicitly created for scalar outputs.\n",
        "\n",
        "If we want it to create for a vector, we have to create a vector of same size"
      ],
      "metadata": {
        "id": "gp-bd_Vz_F9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2\n",
        "print(z)\n",
        "\n",
        "v = torch.zeros_like(z)\n",
        "# v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp4hvZTp9ZKV",
        "outputId": "91f1551b-65a2-4529-89e4-5dc4af8d14c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.8577, 8.5541, 4.8936], grad_fn=<MulBackward0>)\n",
            "tensor([0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dz/dx\n",
        "x = torch.randn(size=(3, ), requires_grad=True)\n",
        "y = x+2\n",
        "z = y*y*2\n",
        "z_mean = z.mean()\n",
        "print(z_mean)\n",
        "z_mean.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-yuNxhz91Sn",
        "outputId": "c1376d39-bbc5-4ca0-9f07-f86075d2143b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5317, grad_fn=<MeanBackward0>)\n",
            "tensor([0.7139, 1.3067, 1.3665])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prevent tracking of gradients:\n",
        "\n",
        "1. x.requires_grad(False)\n",
        "\n",
        "2. x.detach()-> Creates a new tensor that doesn't require the gradient\n",
        "\n",
        "3. with torch.no_grad():"
      ],
      "metadata": {
        "id": "h8Fqrfk3BDGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# Modifies x in-place\n",
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVMfafmcAMI9",
        "outputId": "20d28461-10b9-4667-cf96-a6b8f0075382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9804, 0.7026, 0.8790], requires_grad=True)\n",
            "tensor([0.9804, 0.7026, 0.8790])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H1VUxdYB3Tl",
        "outputId": "2e087a60-0936-46a0-d036-c79035eed541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.0610e-01, 1.6381e-01, 2.5433e-04], requires_grad=True)\n",
            "tensor([4.0610e-01, 1.6381e-01, 2.5433e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = x+2\n",
        "    print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cr1mwpyB-uL",
        "outputId": "7a812670-cfaa-4526-8292-e8207a240726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9053, 0.7492, 0.9062], requires_grad=True)\n",
            "tensor([2.9053, 2.7492, 2.9062])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**backward()** will keep accumulating gradients, i.e sums it up,  until explicilty mentioned not to"
      ],
      "metadata": {
        "id": "FMeJ5k90DjbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(size=(4, ), requires_grad=True)\n",
        "\n",
        "# Dummy operation which simulates w*x+b\n",
        "for epoch in range(1):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "\n",
        "print(\"-\"*50)\n",
        "for epoch in range(2):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niCTPAA9CHNj",
        "outputId": "3c802334-0503-4f35-8388-b2d9b5e78f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "--------------------------------------------------\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To pevent, empty the variable wrt which, grad is being calculated"
      ],
      "metadata": {
        "id": "zES5aVToENCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(size=(4, ), requires_grad=True)\n",
        "\n",
        "# Dummy operation which simulates w*x+b\n",
        "for epoch in range(1):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    weights.grad.zero_()\n",
        "print(\"-\"*50)\n",
        "for epoch in range(2):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    # Emptying the grads\n",
        "    weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmIy6Gk6C0P-",
        "outputId": "56751bec-0490-4c44-ceb6-4c7d947fa69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "--------------------------------------------------\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using optimizers"
      ],
      "metadata": {
        "id": "cVB1P68JEsVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.rand(size=(3, 3), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[weights], lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "Z2zvf_HmEcBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rR-wy4CKFK3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}