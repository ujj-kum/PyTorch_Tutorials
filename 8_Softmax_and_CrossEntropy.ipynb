{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLjubSLf1lD6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "metadata": {
        "id": "lNB_2cIg_VnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([2, 1, 0.1], dtype=np.float32)\n",
        "print(f\"Softmax = {softmax(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfKacCo_Nwl",
        "outputId": "03e16462-3f37-42e0-9e7c-cf1c1d583218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax = [0.6590011  0.24243298 0.09856589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pytorch"
      ],
      "metadata": {
        "id": "GKm_anIi_oOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(x.astype(np.float32))\n",
        "print(f\"Softmax = {torch.softmax(x, dim=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri5OCxbt_S2S",
        "outputId": "331ba65b-82a7-4521-87fb-bde0846d5f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax = tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy"
      ],
      "metadata": {
        "id": "VaKHn3S2Cc00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Rmn-DLWA_1NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 0 is true class\n",
        "y = np.array([1, 0, 0])\n",
        "\n",
        "y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "\n",
        "l1 = cross_entropy(actual=y, predicted=y_pred_good)\n",
        "l2 = cross_entropy(actual=y, predicted=y_pred_bad)\n",
        "\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CytvBDFYCvyS",
        "outputId": "2204c1a0-e73f-4cb7-f985-803bb5d90863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.35667, l2 = 2.30259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pytorch\n",
        "\n",
        "**nn.CrossEntropyLoss() = nn.LogSoftmax + nn.NLLLoss(negative log likelihood loss)**\n",
        "\n",
        "- Don't use Softmax in last layer\n",
        "- Y has class labels, not one-hot encoded\n",
        "- Y_pred has raw scores(logits), no softmax"
      ],
      "metadata": {
        "id": "x6HZ6vqLDZJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "M_NyjTulDWTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([0])\n",
        "\n",
        "# Output will be in shape (n_samples, n_classes), here (1, 3)\n",
        "y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGE9iyR9ERoV",
        "outputId": "46f7fe66-75e9-42e7-dfb0-18aa0d6e8422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.41703, l2 = 1.84062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple samples, 1st sample belongs to 3rd class, 2nd sample belongs to 2nd class and so on..."
      ],
      "metadata": {
        "id": "T-zqLqyRFxCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_values, indices = torch.max(x)"
      ],
      "metadata": {
        "id": "g7Qu3bP3HRAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# Output will be in shape (n_samples, n_classes), here (1, 3)\n",
        "y_pred_good = torch.tensor([[0.1, 1.0, 2.0],\n",
        "                            [2.0, 1.0, 0.1],\n",
        "                            [0.1, 3.0, 1.0]])\n",
        "y_pred_bad = torch.tensor([[2.0, 1.0, 0.1],\n",
        "                          [0.1, 3.0, 1.0],\n",
        "                          [0.1, 1.0, 2.0]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")\n",
        "\n",
        "max_value, indices = torch.max(y_pred_good, dim=1)\n",
        "print(max_value, indices)\n",
        "max_value, indices = torch.max(y_pred_bad, dim=1)\n",
        "print(max_value, indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP-AJ2G6E7T9",
        "outputId": "8ed28601-04c4-4eb3-f12b-3f7e48d58716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.33610, l2 = 2.26944\n",
            "tensor([2., 2., 3.]) tensor([2, 0, 1])\n",
            "tensor([2., 3., 2.]) tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiClass problem"
      ],
      "metadata": {
        "id": "PnavxKniKCBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out1 = self.relu(out)\n",
        "        out2 = self.linear2(out1)\n",
        "        # No softmax at the end\n",
        "        return out2"
      ],
      "metadata": {
        "id": "ESpl4bcZGoE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size=28*28, hidden_size=5, n_classes=3)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "hbCv-oX9K6IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Class Classification"
      ],
      "metadata": {
        "id": "jDPaDMNsMcXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_classes=1):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out1 = self.relu(out)\n",
        "        out2 = self.linear2(out1)\n",
        "        out3 = self.sigmoid(out2)\n",
        "        return out3\n",
        "\n",
        "model = NeuralNet(input_size=28*28, hidden_size=5, n_classes=3)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "dZEalLSCMfo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USzskbbCMvsH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}