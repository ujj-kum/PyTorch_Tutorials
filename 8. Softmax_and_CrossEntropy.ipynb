{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dLjubSLf1lD6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x, here is 1-D array, It has only 1 axis"
      ],
      "metadata": {
        "id": "RBkV3VjExXz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "metadata": {
        "id": "lNB_2cIg_VnG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([2, 1, 0.1], dtype=np.float32)\n",
        "print(f\"Softmax = {softmax(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfKacCo_Nwl",
        "outputId": "816a02a7-3ba5-44ad-9e78-dbd860ac566a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax = [0.6590011  0.24243298 0.09856589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pytorch"
      ],
      "metadata": {
        "id": "GKm_anIi_oOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(x.astype(np.float32))\n",
        "\n",
        "softmax = torch.softmax(x, dim=0)\n",
        "print(f\"Softmax = {softmax}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri5OCxbt_S2S",
        "outputId": "d441ee8d-1b3f-4a38-ad6f-def941ca9435"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax = tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scores/Logits are raw values coming out of last layer"
      ],
      "metadata": {
        "id": "lJTDMI8KyRJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy\n",
        "- Requires the value to be **One Hot Encoded**"
      ],
      "metadata": {
        "id": "VaKHn3S2Cc00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Rmn-DLWA_1NJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 0 is true class(Total 3 class=0, 1 and 2)\n",
        "y = np.array([1, 0, 0])\n",
        "\n",
        "# It is assumed that the below probabilities values are obtained after\n",
        "# Applying Softmax\n",
        "y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "\n",
        "l1 = cross_entropy(actual=y, predicted=y_pred_good)\n",
        "l2 = cross_entropy(actual=y, predicted=y_pred_bad)\n",
        "\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CytvBDFYCvyS",
        "outputId": "54d3821d-747b-4d2a-d6c8-ce18a0e6d017"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.35667, l2 = 2.30259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pytorch\n",
        "\n",
        "**nn.CrossEntropyLoss() = nn.LogSoftmax + nn.NLLLoss(negative log likelihood loss)**\n",
        "\n",
        "- Don't use Softmax in last layer\n",
        "- Y has class labels, not one-hot encoded\n",
        "- Y_pred has raw scores(logits), no softmax"
      ],
      "metadata": {
        "id": "x6HZ6vqLDZJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "M_NyjTulDWTB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([0]) # 0 is the true class\n",
        "\n",
        "# Output will be in shape (n_samples, n_classes), here (1, 3)\n",
        "y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")\n",
        "print(\"#\"*100)\n",
        "print(\"Getting Predictions\")\n",
        "max_value, ind = torch.max(input=y_pred_good, dim=1)\n",
        "print(f\"Value = {max_value.item()}, Index = {ind.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGE9iyR9ERoV",
        "outputId": "53d16854-7e5c-4c52-f868-4aa8671210fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.41703, l2 = 1.84062\n",
            "####################################################################################################\n",
            "Getting Predictions\n",
            "Value = 2.0, Index = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, For multiple samples,\n",
        "- 1st sample belongs to 3rd class\n",
        "- 2nd sample belongs to 1st class  \n",
        "- 3rd sample belongs to 2nd class\n",
        "\n",
        "**length of y = No. of samples**"
      ],
      "metadata": {
        "id": "T-zqLqyRFxCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_values, indices = torch.max(x)"
      ],
      "metadata": {
        "id": "g7Qu3bP3HRAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# Output will be in shape (n_samples, n_classes), here (3, 3)\n",
        "# n_classes can vary(obviously)\n",
        "y_pred_good = torch.tensor([[0.1, 1.0, 2.0],\n",
        "                            [2.0, 1.0, 0.1],\n",
        "                            [0.1, 3.0, 1.0]])\n",
        "y_pred_bad = torch.tensor([[2.0, 1.0, 0.1],\n",
        "                          [0.1, 3.0, 1.0],\n",
        "                          [0.1, 1.0, 2.0]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "print(f\"l1 = {l1:.5f}, l2 = {l2:.5f}\")\n",
        "\n",
        "print(\"For Good prediction\")\n",
        "max_value, indices = torch.max(y_pred_good, dim=1)\n",
        "print(f\"Predicted Values = {max_value}, Predicted Class =  {indices}\")\n",
        "\n",
        "print(\"For Bad prediction\")\n",
        "max_value, indices = torch.max(y_pred_bad, dim=1)\n",
        "print(f\"Predicted Values = {max_value}, Predicted Class =  {indices}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP-AJ2G6E7T9",
        "outputId": "bac411a7-4ad5-4d67-f3d3-1d1ffbf7d555"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1 = 0.33610, l2 = 2.26944\n",
            "For Good prediction\n",
            "Predicted Values = tensor([2., 2., 3.]), Predicted Class =  tensor([2, 0, 1])\n",
            "For Bad prediction\n",
            "Predicted Values = tensor([2., 3., 2.]), Predicted Class =  tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiClass problem"
      ],
      "metadata": {
        "id": "PnavxKniKCBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out1 = self.relu(out)\n",
        "        out2 = self.linear2(out1)\n",
        "        # No softmax at the end\n",
        "        return out2"
      ],
      "metadata": {
        "id": "ESpl4bcZGoE9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size=28*28, hidden_size=5, n_classes=3)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "hbCv-oX9K6IK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Class Classification"
      ],
      "metadata": {
        "id": "jDPaDMNsMcXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_classes=1):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=n_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out1 = self.relu(out)\n",
        "        out2 = self.linear2(out1)\n",
        "        out3 = self.sigmoid(out2)\n",
        "        return out3\n",
        "\n",
        "model = NeuralNet(input_size=28*28, hidden_size=5, n_classes=1)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "dZEalLSCMfo6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USzskbbCMvsH"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}