{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b0eUfkZ83gt-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0) # Input value\n",
        "y = torch.tensor(2.0) # Target value\n",
        "w = torch.tensor(1.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "7M-ilDyp4MCu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward pass"
      ],
      "metadata": {
        "id": "67365F6f8g7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = w*x # Predicted value\n",
        "loss = (y_hat-y)**2\n",
        "print(f\"Loss = {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4gCRUgr8dWN",
        "outputId": "841687cc-e041-4100-f646-a4ba22d1c86f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward pass"
      ],
      "metadata": {
        "id": "x9ynwaC98smv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Computation\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pJqwuFj8pwT",
        "outputId": "89604655-62d9-4f51-e129-c952019a9a6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "QsftE82f_Giq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ju065mnk9CAJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = 2*x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32) # Input\n",
        "# y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "y = 2*X  # Target values\n",
        "w = 0.0 # Intial Weight"
      ],
      "metadata": {
        "id": "Rx32djQV_PB5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward Pass"
      ],
      "metadata": {
        "id": "x4CNY9Bu_8km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return w*x"
      ],
      "metadata": {
        "id": "dXZZGmQG_pdh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating loss"
      ],
      "metadata": {
        "id": "TzfvwFseAGhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, y_pred):\n",
        "    '''\n",
        "    Calculates MSE loss\n",
        "    '''\n",
        "    return ((y_pred-y)**2).mean()"
      ],
      "metadata": {
        "id": "rfNqUuJAAInF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating Gradient manually\n",
        "\n",
        "Derivative of loss wrt w is:\n",
        "\n",
        "$\\frac{dL}{dw} = \\frac{1}{n} (2x \\cdot (y_{\\text{predicted}} - y))$\n"
      ],
      "metadata": {
        "id": "I7O4ajMQBJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(x, y, y_predicted):\n",
        "    '''\n",
        "    Calculates gradient of MSE loss wrt w\n",
        "    '''\n",
        "    return np.dot(2*x, y_pred-y).mean()"
      ],
      "metadata": {
        "id": "8bcrmSZdAcGu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction before training:\\nf(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-y5zjbHCK6m",
        "outputId": "5fdf2435-8026-47a2-af79-c216132b5edf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training:\n",
            "f(5) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "rFAjTIDHC9-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "n_iters = 20\n",
        "print(f\"Initial Weight = {w}\")\n",
        "for epoch in range(1, n_iters+1):\n",
        "    # Prediction = fwd pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # Loss\n",
        "    l = loss(y=y, y_pred=y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = gradient(X, y, y_pred)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr*dw\n",
        "\n",
        "    # Print training info at every step\n",
        "    if epoch%2==0:\n",
        "        print(f\"Epoch {epoch}: w = {w:.3f}, loss={l:.5f}\")\n",
        "\n",
        "print(f\"Prediction after training:\\nf(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdln5KdPCnbw",
        "outputId": "2996ae9c-a314-4a8e-838c-ecdbfdf9e4b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Weight = 0.0\n",
            "Epoch 2: w = 1.680, loss=4.80000\n",
            "Epoch 4: w = 1.949, loss=0.12288\n",
            "Epoch 6: w = 1.992, loss=0.00315\n",
            "Epoch 8: w = 1.999, loss=0.00008\n",
            "Epoch 10: w = 2.000, loss=0.00000\n",
            "Epoch 12: w = 2.000, loss=0.00000\n",
            "Epoch 14: w = 2.000, loss=0.00000\n",
            "Epoch 16: w = 2.000, loss=0.00000\n",
            "Epoch 18: w = 2.000, loss=0.00000\n",
            "Epoch 20: w = 2.000, loss=0.00000\n",
            "Prediction after training:\n",
            "f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating gradient using PyTorch\n",
        "\n",
        "Earlier, we were calculating gradient $\\frac{\\partial w}{\\partial l}$ using the formula. But now, **loss.backward()** autimatically does this for us.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AKs8H8VKF35P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y = 2*X\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "ZX3llyiREGVW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return w*x\n",
        "\n",
        "\n",
        "def loss(y, y_pred):\n",
        "    '''\n",
        "    Calculates MSE loss\n",
        "    '''\n",
        "    return ((y_pred-y)**2).mean()"
      ],
      "metadata": {
        "id": "_GyddroRGOa0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, operations become part of the computational graph when they involve tensors that have **requires_grad=True**\n",
        "\n",
        "Updating weights should not be the part of computational graph"
      ],
      "metadata": {
        "id": "2I6pzjj8HSNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction before training:\\nf(5) = {forward(5):.3f}\")\n",
        "\n",
        "lr = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(1, n_iters+1):\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    # Calculating gradient automatically\n",
        "    # dl/dw\n",
        "    l.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= lr*w.grad\n",
        "\n",
        "    # Zero Grads\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch%10==0:\n",
        "        print(f\"Epoch {epoch}: w = {w:.3f}, loss={l:.5f}\")\n",
        "\n",
        "print(f\"Prediction after training:\\nf(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7S0r4EGt2u",
        "outputId": "c089660d-d38b-4dc5-a5ec-dac1b27e1897"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training:\n",
            "f(5) = 0.000\n",
            "Epoch 10: w = 1.606, loss=1.60939\n",
            "Epoch 20: w = 1.922, loss=0.06238\n",
            "Epoch 30: w = 1.985, loss=0.00242\n",
            "Epoch 40: w = 1.997, loss=0.00009\n",
            "Epoch 50: w = 1.999, loss=0.00000\n",
            "Epoch 60: w = 2.000, loss=0.00000\n",
            "Epoch 70: w = 2.000, loss=0.00000\n",
            "Epoch 80: w = 2.000, loss=0.00000\n",
            "Epoch 90: w = 2.000, loss=0.00000\n",
            "Epoch 100: w = 2.000, loss=0.00000\n",
            "Prediction after training:\n",
            "f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfvE8pRa6pgb"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}