{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CgnEyjYqTYSZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to calculate gradient of some function wrt x. After this Pytorch will calculate a **computation graph**\n",
        "\n",
        "By default, **requires_grad=False**"
      ],
      "metadata": {
        "id": "SIElIiz9To5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(3, ), requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrVTlZHjTfY-",
        "outputId": "e70f3343-a788-4ebc-bf2a-072057e540b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.1159, -0.8031, -2.4649], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A computational graph will be created.\n",
        "\n",
        "Since, + operation is used. Therefore **grad_fn=\\<AddBackward0\\>**"
      ],
      "metadata": {
        "id": "bL3hyLjJ9B-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "id": "t6drPjfCTitc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0ba961-fdbf-4756-b9f0-30bdd01011f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1159,  1.1969, -0.4649], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7a8849cd3f40>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating gradients"
      ],
      "metadata": {
        "id": "x-jaZ2Lv-GfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2\n",
        "print(z)\n",
        "z.backward(x)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7sY3V8WuE6m",
        "outputId": "5113d381-fc3c-4635-c32c-b8489a526c2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0269, 2.8652, 0.4322], grad_fn=<MulBackward0>)\n",
            "tensor([ 0.9813, -3.8449,  4.5832])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a scalar value, gradient can be calculated implicitly"
      ],
      "metadata": {
        "id": "raTstwz7u1Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(size=(1, ), requires_grad=True)\n",
        "y = x**2\n",
        "# dy/dx\n",
        "y.backward() # This calculates dy/dx and returns None\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1yrOTguQPL",
        "outputId": "ca601489-a4dd-4c94-c725-9a649693c028"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**grad can be implicitly created for scalar outputs.**\n",
        "\n",
        "If we want it to create for a vector, we have to create a vector of same size and that vector needs to be passed as **argument in .backward()**\n",
        "\n",
        "**v** provides weightage to how much each element of z, contributes to the gradient and ideally should be a **tensor of 1**"
      ],
      "metadata": {
        "id": "gp-bd_Vz_F9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(size=(3, ), requires_grad=True)\n",
        "y = x**2\n",
        "z = y*y*2\n",
        "print(z)\n",
        "\n",
        "v = torch.ones_like(z)\n",
        "# v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp4hvZTp9ZKV",
        "outputId": "3759b6e9-bb44-4f1c-ed4d-fff949dfcef8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2.], grad_fn=<MulBackward0>)\n",
            "tensor([8., 8., 8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dz/dx\n",
        "x = torch.randn(size=(3, ), requires_grad=True)\n",
        "y = x+2\n",
        "z = y*y*2\n",
        "z_mean = z.mean()\n",
        "print(z_mean)\n",
        "z_mean.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-yuNxhz91Sn",
        "outputId": "b9acf8dc-d381-4cc7-f657-6c209b3a7fb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(15.8178, grad_fn=<MeanBackward0>)\n",
            "tensor([3.4531, 4.9754, 2.3458])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prevent tracking of gradients:\n",
        "\n",
        "1. x.requires_grad(False)\n",
        "\n",
        "2. x.detach()-> Creates a new tensor that doesn't require the gradient\n",
        "\n",
        "3. with torch.no_grad():"
      ],
      "metadata": {
        "id": "h8Fqrfk3BDGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# Modifies x in-place\n",
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVMfafmcAMI9",
        "outputId": "b7b9f005-26e9-4829-c4fd-a560d88716fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5594, 0.7272, 0.6071], requires_grad=True)\n",
            "tensor([0.5594, 0.7272, 0.6071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H1VUxdYB3Tl",
        "outputId": "6a8e9b06-9959-4978-a8f4-6878178a2701"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1746, 0.7210, 0.6549], requires_grad=True)\n",
            "tensor([0.1746, 0.7210, 0.6549])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(3, ), requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = x+2\n",
        "    print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cr1mwpyB-uL",
        "outputId": "81ca06a8-47ee-482c-a964-570fbcdad359"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5700, 0.5308, 0.0444], requires_grad=True)\n",
            "tensor([2.5700, 2.5308, 2.0444])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**backward()** will keep accumulating gradients, i.e sums it up,  until explicilty mentioned not to.\n",
        "\n",
        "Here, each epoch has produced gradient of 3, which is being summed up which previous stored values"
      ],
      "metadata": {
        "id": "FMeJ5k90DjbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(size=(4, ), requires_grad=True)\n",
        "\n",
        "# Dummy operation which simulates w*x+b where b=0\n",
        "for epoch in range(1):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "\n",
        "print(\"-\"*50)\n",
        "for epoch in range(2):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niCTPAA9CHNj",
        "outputId": "3fbf7a0b-8f16-4b97-d683-78b0dc2c8ed7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "--------------------------------------------------\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To pevent, empty the variable wrt which, grad is being calculated"
      ],
      "metadata": {
        "id": "zES5aVToENCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(size=(4, ), requires_grad=True)\n",
        "\n",
        "# Dummy operation which simulates w*x+b\n",
        "for epoch in range(1):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    # Emptying the grads\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(\"-\"*50)\n",
        "for epoch in range(2):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    # Emptying the grads\n",
        "    weights.grad.zero_()\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmIy6Gk6C0P-",
        "outputId": "7b4e7c0e-b67d-46ae-bfd1-ba4b240eb77a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "--------------------------------------------------\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using optimizers"
      ],
      "metadata": {
        "id": "cVB1P68JEsVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.rand(size=(3, 3), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[weights], lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "Z2zvf_HmEcBh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rR-wy4CKFK3q"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}